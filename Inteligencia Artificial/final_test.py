# -*- coding: utf-8 -*-
"""Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SIuxE-mtYLuYINCtMnmDR5e3b-iVicaz

# Trabajo Final: CNN
## Inteligencia Artificial
### Profesor: Cristian López Del Alamo
### CNN: Covid Detection

Base de Datos: [Descargar aquí](https://drive.google.com/file/d/1-RGTR_EEW1Unm2JzMCP7u0lXfenmuQaB/view?usp=sharing)

En la base de datos se tiene 4 folders: COVID, Normal, Lung_Opacity y ViralPneumonia.

Desarrollar un modelo de CNN para identificar si una radiografía de púlmon
es normal, tiene covid, opacidad de pulmón o neumonia.
"""

from pyunpack import Archive
import torch.nn as nn
from torchvision import transforms, datasets
import matplotlib.pyplot as plt
import numpy as np
import math
import os
import torchvision
import torch
from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler
from PIL import Image

#

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)


def get_image_size(image_size, kernel_sizes, stride_sizes=(1, 1, 1), padding_sizes=(2, 2, 2), pooling_sizes=(2, 2, 2)):
    for index in range(len(kernel_sizes)):
        image_size = math.floor((image_size - kernel_sizes[index] + 2 *
                                 padding_sizes[index]) / stride_sizes[index]) + 1
        image_size /= pooling_sizes[index]
    return int(image_size)


# Usted puede cargar un archivo .zip, y de esta forma se desempaqueta. Le creará las carpetas y subcarpetas que existen dentro del zip
# Archive('dataset.zip').extractall('')
print('extracting....')
#Archive('.//content//covid_dataset.zip').extractall('')





""" process_images('normal')
process_images('covid')
process_images('lung_opacity')
process_images('viral_pneumonia')
 """#process_COVID_images()

# Esta función les va a permitir cargar y separar sus imágenes en un test_loader y en un train_loader


def load_images(images_path, batch_size, seed=10):
    transform = transforms.Compose([
        transforms.Grayscale(num_output_channels=1),
        transforms.ToTensor()
    ])
    
    images_dataset = datasets.ImageFolder(images_path, transform=transform)

    train_set_size = int(len(images_dataset) * 0.8)
    valid_set_size = len(images_dataset) - train_set_size

    print('images dataset size', len(images_dataset))
    print('train_set_size', train_set_size)
    print('valid_set_size', valid_set_size)

    train_dataset, test_dataset = random_split(images_dataset, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))
    #train_dataset, test_dataset = random_split(images_dataset, [69, 29], generator=torch.Generator().manual_seed(seed))
    train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=batch_size)
    test_loader = DataLoader(dataset=test_dataset, shuffle=False, batch_size=1)
    
    return train_loader, test_loader


# hyper-parameters
num_classes = 4
learning_rate = 0.0001
num_epochs = 20
batch_size = 1
num_channels = 1  # Número de canales de entrada 

"""# Cree su código de la CNN.
Pruebe con diferentes funciones de activación
"""
"""
class CNN(nn.Module):
    def __init__(self, num_channels, num_classes):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(num_channels, 16, kernel_size=3, stride=1, padding=1)
        self.relu = nn.ReLU()
        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.fc = nn.Linear(32 * 8 * 8, num_classes)

    def forward(self, x):
        x = self.conv1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        x = self.conv2(x)
        x = self.relu(x)
        x = self.maxpool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x
"""""

class CNN(nn.Module):
    def __init__(self, num_channels, num_classes):
        super(CNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(num_channels, 16, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.fc = nn.Sequential(
            nn.Linear(64 * 4 * 4, 128),
            nn.ReLU(),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        #x = F.softmax(x, dim=1) 
        return x
    
def test(model, test_loader):
    model.eval()

    with torch.no_grad():
        correct = 0
        total = 0
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        accuracy = 100 * correct / total
        print('Test Accuracy of the model on the test images: {} %'.format(accuracy))
        
        return accuracy




model = CNN(num_channels, num_classes)

train_loader, test_loader = load_images('preprocessed/', batch_size)
# print(len(train_loader))
# print(len(test_loader))


# Cargar modelo previamente guardo
model.load_state_dict(torch.load('./CNN_covid-88.99.pth'))
test(model,test_loader)
