# -*- coding: utf-8 -*-
"""Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SIuxE-mtYLuYINCtMnmDR5e3b-iVicaz

# Trabajo Final: CNN
## Inteligencia Artificial
### Profesor: Cristian López Del Alamo
### CNN: Covid Detection

Base de Datos: [Descargar aquí](https://drive.google.com/file/d/1-RGTR_EEW1Unm2JzMCP7u0lXfenmuQaB/view?usp=sharing)

En la base de datos se tiene 4 folders: COVID, Normal, Lung_Opacity y ViralPneumonia.

Desarrollar un modelo de CNN para identificar si una radiografía de púlmon
es normal, tiene covid, opacidad de pulmón o neumonia.
"""

from pyunpack import Archive
import torch.nn as nn
from torchvision import transforms, datasets
import matplotlib.pyplot as plt
import numpy as np
import math
import os
import torchvision
import torch
from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler
from PIL import Image

#

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)


def get_image_size(image_size, kernel_sizes, stride_sizes=(1, 1, 1), padding_sizes=(2, 2, 2), pooling_sizes=(2, 2, 2)):
    for index in range(len(kernel_sizes)):
        image_size = math.floor((image_size - kernel_sizes[index] + 2 *
                                 padding_sizes[index]) / stride_sizes[index]) + 1
        image_size /= pooling_sizes[index]
    return int(image_size)


# Usted puede cargar un archivo .zip, y de esta forma se desempaqueta. Le creará las carpetas y subcarpetas que existen dentro del zip
# Archive('dataset.zip').extractall('')
print('extracting....')
#Archive('.//content//covid_dataset.zip').extractall('')


# pip install pyunpack

# Función para graficar las radiografias.
def Show_imgs(imgs, name,  size=3, color=True):
    color_m = 'jet'
    if color == False:
        color_m = 'gray'
    print('******************' + name + '**************************')
    img_numbers = imgs.shape[0]
    rows = cols = math.ceil(np.sqrt(img_numbers))

    fig = plt.figure(figsize=(rows*size, cols*size))
    for i in range(0, rows*cols):
        fig.add_subplot(rows, cols, i+1)
        if i < img_numbers:
            plt.imshow(imgs[i].detach(), cmap='gray')
    plt.show()
# Preprocesamos la data para que todas las imágenes se guarden  en una carpeta prepocessed y además, se escalan para que
# tengan un mismo tamaño,
raw_folder = 'dataset/'
destiny_folder = 'preprocessed/'
if not os.path.exists(destiny_folder):
    os.mkdir(destiny_folder)
    if not os.path.exists(destiny_folder + 'covid/'):
        os.mkdir(destiny_folder + 'covid/')
    if not os.path.exists(destiny_folder + 'normal/'):
        os.mkdir(destiny_folder + 'normal/')
    if not os.path.exists(destiny_folder + 'lung_opacity/'):
        os.mkdir(destiny_folder + 'lung_opacity/')
    if not os.path.exists(destiny_folder + 'viral_pneumonia/'):
        os.mkdir(destiny_folder + 'viral_pneumonia/')


def process_images(name_folder):
    _raw_folder = f'{raw_folder}/'+ name_folder
    _destiny_folder = f'{destiny_folder}/' + name_folder
    print('raw_folder', _raw_folder)
    _, _, images = next(os.walk(_raw_folder))
    for image in images:
        image_path = f"{_raw_folder}/{image}"
        destiny_path = f"{_destiny_folder}/{image}"
        print(f'processing image {image}')
        im = Image.open(image_path)
        #region = im.crop((100, 100, 1024, 1024))
        #grayscale = region.convert('L')
        grayscale = im.convert('L')
        resized = grayscale.resize((256, 256), Image.LANCZOS)
        resized.save(destiny_path)

#---PROCESAMIENTO--**
#process_images('normal')
#process_images('covid')
#process_images('lung_opacity')
#process_images('viral_pneumonia')
#process_COVID_images()

# Esta función les va a permitir cargar y separar sus imágenes en un test_loader y en un train_loader

def load_images(images_path, batch_size, seed=10):
    transform = transforms.Compose([
        transforms.Grayscale(num_output_channels=1),
        transforms.ToTensor()
    ])
    
    images_dataset = datasets.ImageFolder(images_path, transform=transform)

    train_set_size = int(len(images_dataset) * 0.8)
    valid_set_size = len(images_dataset) - train_set_size

    print('images dataset size', len(images_dataset))
    print('train_set_size', train_set_size)
    print('valid_set_size', valid_set_size)

    train_dataset, test_dataset = random_split(images_dataset, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))
    #train_dataset, test_dataset = random_split(images_dataset, [69, 29], generator=torch.Generator().manual_seed(seed))
    train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=batch_size)
    test_loader = DataLoader(dataset=test_dataset, shuffle=False, batch_size=1)
    
    return train_loader, test_loader


# Cargamos el train y el test
train_loader, test_loader = load_images('preprocessed/', batch_size=1)

"""# Cree su código de la CNN.
Pruebe con diferentes funciones de activación
"""

# hypengrparameter
# Parámetros de la red CNN
num_classes = 4
learning_rate = 0.0001
num_epochs = 20
batch_size = 1
num_channels = 1  # Número de canales de entrada 

class CNN(nn.Module):
    def __init__(self, num_channels, num_classes):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(num_channels, 16, kernel_size=3, stride=1, padding=1)
        self.relu = nn.ReLU()
        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.fc = nn.Linear(32 * 8 * 8, num_classes)

    def forward(self, x):
        x = self.conv1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        x = self.conv2(x)
        x = self.relu(x)
        x = self.maxpool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x
""" class CNN(nn.Module):
  # Puede añador parámetros al constructor
  def __init__(self, num_channels, num_classes):
    super(CNN,self).__init__()
    self.layer1 =  nn.Sequential( )


  def forward(self,x):
    out = self.layer1(x)
    return out
 """
    
    
def train(model, train_loader, num_epochs):
    loss_vals = []
    loss_fn = nn.CrossEntropyLoss()  # BCELoss
    print('model.parameters()', model.parameters())
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

    running_loss = 0.0
    total_step = len(train_loader)
    list_loss = []
    list_time = []
    for epoch in range(num_epochs):
        for i, (images, labels) in enumerate(train_loader):
            images = images.to(device)
            labels = labels.to(device)

            output = model(images)
            loss = loss_fn(output, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            list_loss.append(loss.item())
            list_time.append(i)
            i += 1

            if (i+1) % 5 == 0:
                print('Epoch [{}/{}], Step [{}/{}], Loss: {}'
                      .format(epoch+1, num_epochs, i+1, total_step, loss.item()))

    print('Finished Training Trainset')
    return list_loss  # , loss_vals, list_time


# Si debes pasar parámetros recuerda colocarlos dentro de la llamada al constructuro
#model = CNN().to(device)

#model = CNN()
#model = CNN(num_channels, num_classes)

train_loader, test_loader = load_images('preprocessed/', batch_size = 1)
# print(len(train_loader))
# print(len(test_loader))
"""list_loss = train(model, train_loader, num_epochs = 5)

# Aquí graficamos la función Loss y además, realizamos un test
x = [i for i in range(len(list_loss))]
len(x), len(list_loss)
plt.plot(x, list_loss)




# 5. Guardar el modelo entrenado
PATH = './CNN_covid.pth'
torch.save(model.state_dict(), PATH)
plt.show() """
model = CNN(num_channels, num_classes)
model.load_state_dict(torch.load('./CNN_covid.pth'), strict=False)

model.eval()

with torch.no_grad():
    correct = 0
    total = 0
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    print('Test Accuracy of the model on the test images: {} %'.format(
        100 * correct / total))
