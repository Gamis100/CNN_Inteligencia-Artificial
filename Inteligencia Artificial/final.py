# -*- coding: utf-8 -*-
"""Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SIuxE-mtYLuYINCtMnmDR5e3b-iVicaz

# Trabajo Final: CNN
## Inteligencia Artificial
### Profesor: Cristian López Del Alamo
### CNN: Covid Detection

Base de Datos: [Descargar aquí](https://drive.google.com/file/d/1-RGTR_EEW1Unm2JzMCP7u0lXfenmuQaB/view?usp=sharing)

En la base de datos se tiene 4 folders: COVID, Normal, Lung_Opacity y ViralPneumonia.

Desarrollar un modelo de CNN para identificar si una radiografía de púlmon
es normal, tiene covid, opacidad de pulmón o neumonia.
"""

from pyunpack import Archive
import torch.nn as nn
from torchvision import transforms, datasets
import matplotlib.pyplot as plt
import numpy as np
import math
import os
import torchvision
import torch
from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler
from PIL import Image
import torch.nn.functional as F
from sklearn.metrics import confusion_matrix, classification_report

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)


def get_image_size(image_size, kernel_sizes, stride_sizes=(1, 1, 1), padding_sizes=(2, 2, 2), pooling_sizes=(2, 2, 2)):
    for index in range(len(kernel_sizes)):
        image_size = math.floor((image_size - kernel_sizes[index] + 2 *
                                 padding_sizes[index]) / stride_sizes[index]) + 1
        image_size /= pooling_sizes[index]
    return int(image_size)

# Archive('dataset.zip').extractall('')
print('extracting....')
# pip install pyunpack

# Función para graficar las radiografias.
def Show_imgs(imgs, name,  size=3, color=True):
    color_m = 'jet'
    if color == False:
        color_m = 'gray'
    print('******************' + name + '**************************')
    img_numbers = imgs.shape[0]
    rows = cols = math.ceil(np.sqrt(img_numbers))

    fig = plt.figure(figsize=(rows*size, cols*size))
    for i in range(0, rows*cols):
        fig.add_subplot(rows, cols, i+1)
        if i < img_numbers:
            plt.imshow(imgs[i].detach(), cmap='gray')
    plt.show()


# Preprocesamos la data para que todas las imágenes se guarden  en una carpeta prepocessed y además, se escalan para que
# tengan un mismo tamaño,
raw_folder = 'dataset/'
destiny_folder = 'preprocessed/'
if not os.path.exists(destiny_folder):
    os.mkdir(destiny_folder)
    if not os.path.exists(destiny_folder + 'covid/'):
        os.mkdir(destiny_folder + 'covid/')
    if not os.path.exists(destiny_folder + 'normal/'):
        os.mkdir(destiny_folder + 'normal/')
    if not os.path.exists(destiny_folder + 'lung_opacity/'):
        os.mkdir(destiny_folder + 'lung_opacity/')
    if not os.path.exists(destiny_folder + 'viral_pneumonia/'):
        os.mkdir(destiny_folder + 'viral_pneumonia/')


def process_images(name_folder):
    _raw_folder = f'{raw_folder}/'+ name_folder
    _destiny_folder = f'{destiny_folder}/' + name_folder
    print('raw_folder', _raw_folder)
    _, _, images = next(os.walk(_raw_folder))
    for image in images:
        image_path = f"{_raw_folder}/{image}"
        destiny_path = f"{_destiny_folder}/{image}"
        print(f'processing image {image}')
        im = Image.open(image_path)
        ##region = im.crop((100, 100, 1024, 1024))
        #grayscale = region.convert('L')
        grayscale = im.convert('L')
        resized = grayscale.resize((32, 32), Image.LANCZOS)
        resized.save(destiny_path)

""" process_images('normal')
process_images('covid')
process_images('lung_opacity')
process_images('viral_pneumonia')
 """#process_COVID_images()

# Esta función les va a permitir cargar y separar sus imágenes en un test_loader y en un train_loader


def load_images(images_path, batch_size, seed=10):
    transform = transforms.Compose([
        transforms.Grayscale(num_output_channels=1),
        transforms.ToTensor()
    ])
    
    images_dataset = datasets.ImageFolder(images_path, transform=transform)

    train_set_size = int(len(images_dataset) * 0.8)
    valid_set_size = len(images_dataset) - train_set_size

    print('images dataset size', len(images_dataset))
    print('train_set_size', train_set_size)
    print('valid_set_size', valid_set_size)

    train_dataset, test_dataset = random_split(images_dataset, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))
    #train_dataset, test_dataset = random_split(images_dataset, [69, 29], generator=torch.Generator().manual_seed(seed))
    train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=batch_size)
    test_loader = DataLoader(dataset=test_dataset, shuffle=False, batch_size=1)
    return train_loader, test_loader

# hyper-parameters
num_classes = 4
learning_rate = 0.0001
num_epochs = 20
batch_size = 1
num_channels = 1  # Número de canales de entrada 

"""# Cree su código de la CNN.
Pruebe con diferentes funciones de activación
"""
"""""
class CNN(nn.Module):
    def __init__(self, num_channels, num_classes):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(num_channels, 16, kernel_size=3, stride=1, padding=1)
        self.relu = nn.ReLU()
        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.fc = nn.Linear(32 * 8 * 8, num_classes)

    def forward(self, x):
        x = self.conv1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        x = self.conv2(x)
        x = self.relu(x)
        x = self.maxpool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

"""
class CNN(nn.Module):
    def __init__(self, num_channels, num_classes):
        super(CNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(num_channels, 16, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.fc = nn.Sequential(
            nn.Linear(64 * 4 * 4, 128),
            nn.ReLU(),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        #x = F.softmax(x, dim=1) 
        return x
    
def test(model, test_loader):
    model.eval()

    with torch.no_grad():
        correct = 0
        total = 0
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        accuracy = 100 * correct / total
        print('Test Accuracy of the model on the test images: {} %'.format(accuracy))
        
        return accuracy

def train(model, train_loader, test_loader, num_epochs):
    loss_vals = []
    loss_fn = nn.CrossEntropyLoss()  
    print('model.parameters()', model.parameters())
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

    running_loss = 0.0
    total_step = len(train_loader)
    list_loss = []
    list_time = []
    max_accuracy = 0
    for epoch in range(num_epochs):
        for i, (images, labels) in enumerate(train_loader):
            images = images.to(device)
            labels = labels.to(device)

            output = model(images)
            loss = loss_fn(output, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            list_loss.append(loss.item())
            list_time.append(i)
            i += 1

            if (i+1) % 500 == 0:
                print('Epoch [{}/{}], Step [{}/{}], Loss: {}'
                      .format(epoch+1, num_epochs, i+1, total_step, loss.item()))


        if epoch == 10:
            for param_group in optimizer.param_groups:
                print("decreasing the learning rate")
                param_group['lr'] = 0.00005

        test_acc = test(model, test_loader)
        if test_acc > max_accuracy:
            max_accuracy = test_acc
            PATH = './CNN_covid-' + str(round(test_acc, 2)) + '.pth'
            torch.save(model.state_dict(), PATH)
            print('Model saved')


    print('Finished Training Trainset')
    return list_loss  # , loss_vals, list_time


model = CNN(num_channels, num_classes)

train_loader, test_loader = load_images('preprocessed/', batch_size)
# print(len(train_loader))
# print(len(test_loader))
list_loss = train(model, train_loader, test_loader, num_epochs)

# Aquí graficamos la función Loss y además, realizamos un test
x = [i for i in range(len(list_loss))]
len(x), len(list_loss)
plt.plot(x, list_loss)

plt.show() 

def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized Confusion Matrix")
    else:
        print('Confusion Matrix, without normalization')

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(j, i, format(cm[i, j], fmt), horizontalalignment="center", color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()

# Obtener las predicciones del modelo en el conjunto de prueba
model.eval()
predictions = []
true_labels = []
with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        predictions.extend(predicted.cpu().numpy())
        true_labels.extend(labels.cpu().numpy())

# Calcular la matriz de confusión
cm = confusion_matrix(true_labels, predictions)

# Definir los nombres de las clases
class_names = ['COVID', 'Normal', 'Lung Opacity', 'Viral Pneumonia']

# Graficar la matriz de confusión
plt.figure(figsize=(8, 6))
plot_confusion_matrix(cm, class_names, normalize=False)
plt.show()

